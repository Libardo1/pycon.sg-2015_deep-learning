<!doctype html>
<html lang="en">

 <head>
  <meta charset="utf-8">

  <title>Going Deeper with Python & Theano</title>

  <meta name="description" content="Presentation on Theano for PyCon.SG 2015">
  <meta name="author" content="Martin Andrews">

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <link rel="stylesheet" href="css/reveal.min.css">
  <link rel="stylesheet" xhref="css/theme/default.css" href="css/theme/sky.css" id="theme">

  <!-- For syntax highlighting -->
  <link rel="stylesheet" href="lib/css/zenburn.css">

  <!-- If the query includes 'print-pdf', include the PDF print sheet -->
  <script>
   if( window.location.search.match( /print-pdf/gi ) ) {
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = 'css/print/pdf.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
   }
  </script>

  <!--[if lt IE 9]>
  <script src="lib/js/html5shiv.js"></script>
  <![endif]-->
 </head>

 <body>
  <div class="reveal">
   <!-- Any section element inside of this container is displayed as a slide -->
   <div class="slides">
    
<style>
table.table-fix {
 margin-left:auto;  margin-right:auto; border-collapse:collapse; cell-padding:5px;
 margin-top:20px;
}
.table-fix td,.table-fix th {
 padding: 6px;
}
.table-fix th {
 border-bottom:1pt solid black;
}
.fix-spacing li {
 margin-bottom:16pt;
}
</style>

<!--
## Target : 35-45 mins

Intro : Me

Intro : Motivation
  History of the field
  Why it's exciting now
  Who's involved

Intro: Basic Network
  Diagram => Matrix multiply
  Training == differentiation
    so : need more than numpy 
  Theano as computation description 

Intro: MNIST
  More complex set of operations
  Parse tree from Theano
  CPU output

Intro: ConvNets
  Convnet blocks
  Size of problems
  GPU output
  Diagram of an ~AlexNet


Intro: 'blocks' for Theano
  Overlay on top of Theano
    Make deeper networks simpler to describe
  Maps to whole langauge of DNN
    Different kinds of 
      initializations
        constants
        gaussians 
        orthonormals
      sigmoids
        tanh
        ReLU ...
      gradient descent methods 
        momentum
        ADAgrad ...
      cost functions
  LivePlotting Example

Intro: RecurrentNets
  Applications:
    Audio in phones
    Translation
  Surprising that these automata can also be trained
    Need lots of data
    'blocks' language can describe it all

"Demo" : Examples from character-by-character
  10
  100
  1000
  
Intro: WordEmbedding
  word2vec and gensim
    Ought to mention since it's very competitive
  
What is in the REPO
  Notes on installing blocks "bleeding edge"
    NB : Fairly large downloads...
  iPython
    graphing
    character-by-character
  Please star

 
 
Explain Approach
  WordEmbedding
    How this is exciting
  Getting the vectors
    word2vec
    GloVE

Explain Theano
  Python module that describes relationships
    Implements through numpy and GPU
    GPU : CUDA and OpenCL routes
  Simple idea
    Code example  
  Show updates
    Symbolic differentiation 'for free'
    Code example
  'lasagne' deep learning setup too
    Code example
  
Explain Theano Implementation
  GPU consideration : Bus bandwidth
  Need to do Word Embedding trick on-GPU
  Paging in of training set

Status
  What exists
    Already learning gap-detection
  Next Steps
    Maybe also do fill-in model
    Open Source in ~ 1 week

End
!-->

<section>
 <h1>Going Deeper</h1>
 <h3>with Python & Theano</h3>
 <p>
  <small><a href="http://mdda.net">Martin Andrews</a> / <a href="http://twitter.com/redcatlabs">@redcatlabs</a></small>
 </p>
 <p>
  <small>19 June 2015</small>
 </p>
</section>


<section>
 <h2><strike>Machine</strike> Deep Learning</h2>
</section>


<section>
 <h2>About Me</h2>
 <ul class="fix-spacing">
  <li>Finance / Startups / Machine Learning</li>
  <li style="list-style-type:none">
    <ul>
      <li>Moved to Singapore in Sep-2013</li>
    </ul>
  </li>
  <li>The past year (2014) = 'fun' :</li>
  <li style="list-style-type:none">
    <ul>
      <li>Machine Learning : Deep Learning, NLP</li>
      <li>Languages : Python, Go, Scala, NodeJS, Haskell, Python</li>
      <li>"MeetUp Pro"</li>
    </ul>
  </li>
  <li>This year (2015) = 'serious' NLP</li>
 </ul>
</section>


<section>
 <h2>Talk Outline</h2>
 <ul class="fix-spacing">
  <li>What people are doing</li>
  <li>Why Python / Theano / ++ ?</li>
  <li>Demos &amp; Code</li>
 </ul>
 <p><i>In a random order...</i></p>
</section>

<section>
  <section>
   <h2>Deep Learning</h2>
   <ul class="fix-spacing">
    <li>Neural Networks</li>
    <li>Multiple layers</li>
    <li>Fed with lots of Data</li>
   </ul>
  </section>
  <section>
   <h2>History</h2>
   <ul class="fix-spacing">
    <li>1980+ : Lots of enthusiasm for NNs</li>
    <li>1995+ : Disillusionment = AI Winter (2+)</li>
    <li>2005+ : Stepwise improvement : Depth</li>
    <li>2010+ : GPU revolution : Data</li>
   </ul>
  </section>
  <section>
   <h2>Who is involved</h2>
   <ul class="fix-spacing">
    <li>Google - Hinton (Toronto)</li>
    <li>Facebook - LeCun (NYC)</li>
    <li>Baidu - Ng (Stanford)</li>
    <li>... Apple (aquisitions), etc</li>
    <li>Universities, eg: Montreal (Bengio)</li>
   </ul>
  </section>
</section>


<section>
  <section>
   <h2>Basic Approach</h2>
   <ul class="fix-spacing">
    <li>Same as original Neural Networks in 1980s/1990s</li>
    <li>Simple mathematical units ...</li>
    <li style="list-style-type:none"> ... combine to compute a complex function</li>
    <li>Focus on Supervised Learning here</li>
   </ul>
  </section>

  <section>
   <h2>Single "Neuron"</h2>
   <img width="602" height="381" src="img/one-neuron_602x381.png" alt="One Neuron" style="border:none;box-shadow:none">
   <p>Change weights to change output function</p>
  </section>

  <section>
   <h2>Multi-Layer</h2>
   <p>Layers of neurons combine and <br/>can form more complex functions</p>
   <img width="356" height="324" src="img/multi-layer_356x324.png" alt="Multi-Layer" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Supervised Learning</h2>
   <ul class="fix-spacing">
    <li><strong>while</strong> not done :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Pick a training case (<code>x</code> &rarr; <code>target_y</code>)</li>
        <li>Evaluate <code>output_y</code> from the <code>x</code></li>
        <li>Modify the weights so that <code>output_y</code> is closer to <code>target_y</code> for that <code>x</code></li>
      </ul>
    </li>
   </ul>
  </section>

  <section>
   <h2>Gradient Descent</h2>
   <p>Follow the gradient of the error <br />w.r.t the connection weights</p>
   <img width="364" height="306" src="img/gradient-descent_364x306.png" alt="Gradient-Descent" style="border:none;box-shadow:none">
  </section>
</section>


<section>
  <section>
   <h2>"Hello World" &rarr; MNIST</h2>
   <ul class="fix-spacing">
    <li>Nice dataset from the late 1990s</li>
    <li>Training set of 50,000 28x28 images</li>
    <li>Now end-of-life as a useful benchmark</li>
   </ul>
   <br />
   <img width="255" height="204" src="img/mnist_100_digits_255x204.png" alt="MNIST digits" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Simple Network</h2>
   <img width="829" height="425" src="img/netvis-mnist-100S_829x425.png" alt="Multi-Layer" style="border:none;box-shadow:none">
   <p><i>... around 2-3% error rate on the test set</i></p>
  </section>
  
  <section>
   <h2>"LeNet"</h2>
   <img width="759" height="209" src="img/lenet5_759x209.png" alt="LeNet5 Convolutional Layers" style="border:none;box-shadow:none">
   <p><i>... around 0.8% error rate on the test set</i></p>
  </section>
</section>

<section>
  <section>
   <h2>New Problems</h2>
   <ul class="fix-spacing">
    <li>ImageNet Competition</li>
    <li>over 15 million labeled high-resolution images...</li>
    <li style="list-style-type:none"> ... in over 22,000 categories</li>
   </ul>
   <br />
   <img width="850" height="314" src="img/ilsvrc1_850x314.png" alt="ImageNet Karpathy" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Need for Speed</h2>
   <img width="759" height="408" src="img/CPU-GPU_759x408.png" alt="CPU vs GPU" style="border:none;box-shadow:none">
   <p><i>... need for GPU programmers</i></p>
  </section>
</section>


<section>
  <section>
   <h2>Python</h2>
   <ul class="fix-spacing">
    <li>Great for high-level glue-code</li>
    <li>Increasingly used in research: </li>
    <li style="list-style-type:none">
      <ul>
        <li>iPython</li>
        <li style="list-style-type:none"> + bokeh (visualisation)</li>
        <li>Theano</li>
        <li style="list-style-type:none"> + blocks + fuel</li>
      </ul>
    </li>
    <li>Huge, supportive community</li>
   </ul>
  </section>
  
  <section>
   <h2>Theano</h2>
   <ul class="fix-spacing">
    <li>Optimised Numerical Computation in Python</li>
    <li>Computation is <em>described</em> in Python code :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Theano operates on expression tree itself</li>
        <li>Optimizes the tree for operations it knows</li>
        <li>Makes use of <code>numpy</code> and <code>BLAS</code></li>
        <li>Also writes <code>C/C++</code> or <code>CUDA</code> (or <code>OpenCL</code>)</li>
      </ul>
    </li>
   </ul>
  </section>
  
  <section>
   <h2>Graphing Demo</h2>
  </section>
  
  <section>
   <h2>Theano : Basic</h2>
   <p>Function 'built up', then evaluated</p>
   <pre><code data-trim contenteditable>
import theano.tensor as T
x = T.matrix("x") # Declare Theano symbolic variables
y = T.vector("y")
w = theano.shared(rng.randn(feats), name="w")
b = theano.shared(0., name="b")

# Construct Theano expression graph
p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))   # Probability that target = 1
prediction = p_1 > 0.5                    # The prediction thresholded

predict = theano.function(inputs=[x], outputs=prediction)

print predict( [0.1, .02, ... , -7.4, 3.2] )
   </code></pre>
  </section>
  <section>
   <h2>Theano : Iterative</h2>
   <p>Gradients come 'free'</p>
   <pre><code data-trim contenteditable>
xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss fn
cost = xent.mean() + 0.01 * (w ** 2).sum()    # Minimize this

gw, gb = T.grad(cost, [w, b])  # Compute the gradient of the cost

train = theano.function( 
          inputs=[x,y],
          outputs=[prediction, xent],
          updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))

for i in xrange(training_steps):
    pred, err = train(data_X, data_y)   
   </code></pre>
  </section>
</section>


<section>
  <section>
   <h2>More Complex Networks</h2>
   <img width="698" height="217" src="img/google-imagenet_698x217.png" alt="Google ImageNet" style="border:none;box-shadow:none">
   <p><i>(now human competitive on ImageNet)</i></p>
  </section>
  
  <section>
   <h2>'blocks' for Theano</h2>
   <ul class="fix-spacing">
    <li>Overlay on top of Theano</li>
    <li>DSL to describe deep networks : </li>
    <li style="list-style-type:none">
      <ul>
        <li>Initialization : <code>Constant</code>, <code>Gaussian</code>, <code>Orthonormal</code>, ...</li>
        <li>Sigmoids : <code>Tanh</code>, <code>ReLU</code>, ...</li>
        <li>Gradient Descent : <code>Momentum</code>, <code>ADAgrad</code>, ...</li>
        <li>Cost Functions : <code>CategoricalCrossEntropy</code>, ...</li>
        <li>Misc : <code>BeamSearch</code>, ...</li>
      </ul>
    </li>
   </ul>
  
  </section>
</section>

<section>
  <section>
   <h2>Recurrent Neural Networks</h2>
   <img width="698" height="217" src="img/google-imagenet_698x217.png" alt="Google ImageNet" style="border:none;box-shadow:none">
  </section>
  
  <section>
   <h2>'blocks' for Theano</h2>
   <ul class="fix-spacing">
    <li>Overlay on top of Theano</li>
    <li>DSL to describe deep networks : </li>
    <li style="list-style-type:none">
      <ul>
        <li>Initialization : <code>Constant</code>, <code>Gaussian</code>, <code>Orthonormal</code>, ...</li>
        <li>Sigmoids : <code>Tanh</code>, <code>ReLU</code>, ...</li>
        <li>Gradient Descent : <code>Momentum</code>, <code>ADAgrad</code>, ...</li>
        <li>Cost Functions : <code>CategoricalCrossEntropy</code>, ...</li>
        <li>Misc : <code>BeamSearch</code>, ...</li>
      </ul>
    </li>
   </ul>
  
  </section>
</section>


<section>
 <h2>Wrap-up</h2>
 <ul class="fix-spacing">
  <li>Theano makes GPUs Python-friendly</li>
  <li style="list-style-type:none">
    <ul>
      <li><em>(all code already on GitHub)</em></li>
    </ul>
  </li>
 </ul>
</section>


<section>
 <h1>- QUESTIONS -</h1>
 <br>
 <h3>Martin.Andrews @<br> RedCatLabs.com</h3>
 <br>
 <p>( <a href="https://github.com/mdda">'mdda' on GitHub!</a> )</p>
</section>

   </div>
  </div>

<div id="redcatlabs-logo" style="background: url(img/redcatlabs_logo1_280x39.png);
                                  position: absolute;
                                  bottom: 50px;
                                  left: 50px;
                                  width: 280px;
                                  height: 39px;">
</div>  

  <script src="lib/js/head.min.js"></script>
  <script src="js/reveal.min.js"></script>

  <script>

   // Full list of configuration options available here:
   // https://github.com/hakimel/reveal.js#configuration
   Reveal.initialize({
    controls: true,
    progress: true,
    history: true,
    center: true,

    theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
    transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

    // Parallax scrolling
    // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
    // parallaxBackgroundSize: '2100px 900px',

    // Optional libraries used to extend on reveal.js
    dependencies: [
     { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
     { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
     { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
     { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
     { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
     { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
    ]
   });

  </script>

 </body>
</html>
