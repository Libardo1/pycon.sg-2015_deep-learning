<!doctype html>
<html lang="en">

 <head>
  <meta charset="utf-8">

  <title>Theano for the Billion Word Kaggle</title>

  <meta name="description" content="Presentation on Theano for PyCon.SG 2015">
  <meta name="author" content="Martin Andrews">

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <link rel="stylesheet" href="css/reveal.min.css">
  <link rel="stylesheet" xhref="css/theme/default.css" href="css/theme/sky.css" id="theme">

  <!-- For syntax highlighting -->
  <link rel="stylesheet" href="lib/css/zenburn.css">

  <!-- If the query includes 'print-pdf', include the PDF print sheet -->
  <script>
   if( window.location.search.match( /print-pdf/gi ) ) {
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = 'css/print/pdf.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
   }
  </script>

  <!--[if lt IE 9]>
  <script src="lib/js/html5shiv.js"></script>
  <![endif]-->
 </head>

 <body>
  <div class="reveal">
   <!-- Any section element inside of this container is displayed as a slide -->
   <div class="slides">
    
<style>
table.table-fix {
 margin-left:auto;  margin-right:auto; border-collapse:collapse; cell-padding:5px;
 margin-top:20px;
}
.table-fix td,.table-fix th {
 padding: 6px;
}
.table-fix th {
 border-bottom:1pt solid black;
}
.fix-spacing li {
 margin-bottom:16pt;
}
</style>

<!--
## Target : 35-45 mins

Intro : Me

Intro : Motivation
  History of the field
  Why it's exciting now
  Who's involved

Intro: Basic Network
  Diagram => Matrix multiply
  Training == differentiation
    so : need more than numpy 
  Theano as computation description 

Intro: MNIST
  More complex set of operations
  Parse tree from Theano
  CPU output

Intro: ConvNets
  Convnet blocks
  Size of problems
  GPU output
  Diagram of an ~AlexNet

Intro: 'blocks' for Theano
  Overlay on top of Theano
    Make deeper networks simpler to describe
  Maps to whole langauge of DNN
    Different kinds of 
      initializations
        constants
        gaussians 
        orthonormals
      sigmoids
        tanh
        ReLU ...
      gradient descent methods 
        momentum
        ADAgrad ...
      cost functions
  LivePlotting Example

Intro: RecurrentNets
  Applications:
    Audio in phones
    Translation
  Surprising that these automata can also be trained
    Need lots of data
    'blocks' language can describe it all

"Demo" : Examples from character-by-character
  10
  100
  1000
  
Intro: WordEmbedding
  word2vec and gensim
    Ought to mention since it's very competitive
  
What is in the REPO
  Notes on installing blocks "bleeding edge"
    NB : Fairly large downloads...
  iPython
    graphing
    character-by-character
  Please star

 
 
Explain Approach
  WordEmbedding
    How this is exciting
  Getting the vectors
    word2vec
    GloVE

Explain Theano
  Python module that describes relationships
    Implements through numpy and GPU
    GPU : CUDA and OpenCL routes
  Simple idea
    Code example  
  Show updates
    Symbolic differentiation 'for free'
    Code example
  'lasagne' deep learning setup too
    Code example
  
Explain Theano Implementation
  GPU consideration : Bus bandwidth
  Need to do Word Embedding trick on-GPU
  Paging in of training set

Status
  What exists
    Already learning gap-detection
  Next Steps
    Maybe also do fill-in model
    Open Source in ~ 1 week

End
!-->

<section>
 <h1>Going Deeper</h1>
 <h3>with Python & Theano</h3>
 <p>
  <small><a href="http://mdda.net">Martin Andrews</a> / <a href="http://twitter.com/redcatlabs">@redcatlabs</a></small>
 </p>
 <p>
  <small>19 June 2015</small>
 </p>
</section>


<section>
 <h2><strike>Machine</strike> Deep Learning</h2>
</section>


<section>
 <h2>About Me</h2>
 <ul class="fix-spacing">
  <li>Finance / Startups / Machine Learning</li>
  <li style="list-style-type:none">
    <ul>
      <li>Moved to Singapore in Sep-2013</li>
    </ul>
  </li>
  <li>The past year (2014) = 'fun' :</li>
  <li style="list-style-type:none">
    <ul>
      <li>Machine Learning : Deep Learning, NLP</li>
      <li>Languages : Python, Go, Scala, NodeJS, Haskell, Python</li>
      <li>"MeetUp Pro"</li>
    </ul>
  </li>
  <li>This year (2015) = 'serious' NLP</li>
 </ul>
</section>


<section>
 <h2>Talk Outline</h2>
 <ul class="fix-spacing">
  <li>What people are doing</li>
  <li>Why Python / Theano / ++ ?</li>
  <li>Demos &amp; Code</li>
 </ul>
 <p><i>In a random order...</i></p>
</section>

<section>
  <section>
   <h2>Deep Learning</h2>
   <ul class="fix-spacing">
    <li>Neural Networks</li>
    <li>Multiple layers</li>
    <li>Fed with lots of Data</li>
   </ul>
  </section>
  <section>
   <h2>History</h2>
   <ul class="fix-spacing">
    <li>1980+ : Lots of enthusiasm for NNs</li>
    <li>1995+ : Disillusionment = AI Winter (2+)</li>
    <li>2005+ : Stepwise improvement : Depth</li>
    <li>2010+ : GPU revolution : Data</li>
   </ul>
  </section>
  <section>
   <h2>Who is involved</h2>
   <ul class="fix-spacing">
    <li>Google - Hinton (Toronto)</li>
    <li>Facebook - LeCun (NYC)</li>
    <li>Baidu - Ng (Stanford)</li>
    <li>... Apple (aquisitions), etc</li>
    <li>Universities, eg: Montreal (Bengio)</li>
   </ul>
  </section>
</section>

<section>
  <section>
   <h2>My Basic Approach</h2>
   <ul class="fix-spacing">
    <li>Find where there's a word missing</li>
    <li>For that position think up a word</li>
    <li>Apply Deep Learning to score possibilities</li>
   </ul>
   <img width="700" height="131" src="img/img-to-cat_700x131.png" alt="Image to Cat" style="border:none;box-shadow:none">
  </section>
  <section>
   <h2>Word Embedding</h2>
   <p>How to handle 'discrete' things like Words?</p>
   <img width="732" height="360" src="img/word-embedding_732x360.png" alt="Word Embedding" style="border:none;box-shadow:none">
  </section>
  <section>
   <h2>Trainable on Wikipedia</h2>
   <img width="700" height="267" src="img/embedding-training_700x267.png" alt="Word Embedding Training" style="border:none;box-shadow:none">
   <p>5.7MM documents, 5.4Bn terms<br />&rarr; 155k words, 500-D embedding</p>
  </section>
  <section>
   <h2>Finds Relationships</h2>
   <img width="446" height="360" src="img/facts_446x360.png" alt="Word Embedding Facts" style="border:none;box-shadow:none">
   <p>Ready-made Python module : Word2Vec</p>
  </section>
  <section>
   <h2>Semantic too</h2>
   <img width="535" height="289" src="img/grammar_535x289.png" alt="Word Embedding Grammar" style="border:none;box-shadow:none">
   <p>This is pretty surprising, IMHO</p>
  </section>
</section>

<section>
  <section>
   <h2>Theano</h2>
   <ul class="fix-spacing">
    <li>Optimised Numerical Computation in Python</li>
    <li>Works in conjunction with <code>numpy</code></li>
    <li>Computation is <em>described</em> in Python code :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Theano operates on expression tree itself</li>
        <li>Optimizes the tree for operations it knows</li>
        <li>Implements it in <code>C/C++</code> or <code>CUDA</code> (or <code>OpenCL</code>)</li>
      </ul>
    </li>
   </ul>
  </section>
  <section>
   <h2>Theano : Basic</h2>
   <p>Function 'built up', then evaluated</p>
   <pre><code data-trim contenteditable>
import theano.tensor as T
x = T.matrix("x") # Declare Theano symbolic variables
y = T.vector("y")
w = theano.shared(rng.randn(feats), name="w")
b = theano.shared(0., name="b")

# Construct Theano expression graph
p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))   # Probability that target = 1
prediction = p_1 > 0.5                    # The prediction thresholded

predict = theano.function(inputs=[x], outputs=prediction)

print predict( [0.1, .02, ... , -7.4, 3.2] )
   </code></pre>
  </section>
  <section>
   <h2>Theano : Iterative</h2>
   <p>Gradients come 'free'</p>
   <pre><code data-trim contenteditable>
xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss fn
cost = xent.mean() + 0.01 * (w ** 2).sum()    # Minimize this

gw, gb = T.grad(cost, [w, b])  # Compute the gradient of the cost

train = theano.function( 
          inputs=[x,y],
          outputs=[prediction, xent],
          updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))

for i in xrange(training_steps):
    pred, err = train(data_X, data_y)   
   </code></pre>
   <p>Iteration mechanism built-in</p>
  </section>
  <section>
   <h2>Theano : Lasagne</h2>
   <p>Thin 'NN' layer on top of regular Theano</p>
   <pre><code data-trim contenteditable>
l_in = lasagne.layers.InputLayer(
    shape=(batch_size, 1, input_width, input_height) )
    
l_conv2 = cuda_convnet.Conv2DCCLayer( l_in,
    num_filters=32, filter_size=(5, 5),
    nonlinearity=lasagne.nonlinearities.rectify )
    
l_pool2 = cuda_convnet.MaxPool2DCCLayer( l_conv2, ds=(2, 2))

l_hidden = lasagne.layers.DenseLayer( l_pool2, num_units=256,
    nonlinearity=lasagne.nonlinearities.rectify )

l_dropout = lasagne.layers.DropoutLayer(l_hidden, p=0.5)

l_out = lasagne.layers.DenseLayer( l_dropout, num_units=output_dim,
    nonlinearity=lasagne.nonlinearities.softmax )
   </code></pre>
  </section>
</section>


<section>
  <section>
   <h2>1Bn Words ...</h2>
   <ul class="fix-spacing">
    <li>Size of DataSet is a problem</li>
    <li>Word-Embedding is 'new'</li>
    <li>Playing around with 'gaps' objective</li>
   </ul>
  </section>
  <section>
   <h2>DataSet size</h2>
   <ul class="fix-spacing">
    <li>Reduce training set to manageable size during dev.</li>
    <li>Even so, 1MM sentences &rArr; 40MM training examples</li>
    <li>Will eventually need to page data into GPU</li>
    <li>Need to consider PCI bus bandwidth (epochs, etc)</li>
   </ul>
  </section>
  <section>
   <h2>Word Embedding</h2>
   <ul class="fix-spacing">
    <li>vocab.size &gt; 65k &rArr; word[&middot;] : int32</li>
    <li>Training examples :</li>
    <li style="list-style-type:none">
     <ul>
      <li>( word[i-1], word[i] ) &rarr; ( gap_type=0 )</li>
      <li>( word[i-1], word[i+1] ) &rarr; ( gap_type>0 )</li>
     </ul>
    </li>
    <li>Store 240-D vectors on GPU (150Mb)</li>
    <li>Expand word-context to 480-D input vector</li>
   </ul>
  </section>
  <section>
   <h2>Gaps objective</h2>
   <ul class="fix-spacing">
    <li><code>gap_type</code> is softmax over 2+32 classes : </li>
    <li style="list-style-type:none">
      <ul>
        <li>{ NoGap, ComplexGap } ++ </li>
        <li>{ the , . to of a and in {N} " that 's for on is was with ... }</li>
      </ul>
    </li>
    <li>Base case for <code>gap.best</code> &rArr; add a space</li>
    <li>Filling known gap with uncertain word &rArr; Risky</li>
   </ul>
   <ximg width="700" height="131" src="img/img-to-cat_700x131.png" alt="Image to Cat" style="border:none;box-shadow:none">
  </section>
</section>

<section>
  <section>
   <h2>Wrap-up</h2>
   <ul class="fix-spacing">
    <li>Kaggle Competitions are Cool</li>
    <li>Word Embedding is Surprising</li>
    <li>Theano makes GPUs Python-friendly</li>
    <li><em>Will "Formally Announce" ASAP</em></li>
    <li style="list-style-type:none">
      <ul>
        <li><em>(all code already on GitHub)</em></li>
      </ul>
    </li>
   </ul>
  </section>
  <section>
   <h2>The Future</h2>
   <ul class="fix-spacing">
    <li>This coming year (2015) = 'serious' :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Working for Local Company</li>
        <li>Sole Focus : NLP (financial documents &rarr; relationships)</li>
      </ul>
    </li>
   </ul>
  </section>
</section>


<section>
 <h1>- QUESTIONS -</h1>
 <br>
 <h3>Martin.Andrews @<br> RedCatLabs.com</h3>
 <br>
 <p>( <a href="https://github.com/mdda">'mdda' on GitHub!</a> )</p>
</section>

   </div>
  </div>

<div id="redcatlabs-logo" style="background: url(img/redcatlabs_logo1_280x39.png);
                                  position: absolute;
                                  bottom: 50px;
                                  left: 50px;
                                  width: 280px;
                                  height: 39px;">
</div>  

  <script src="lib/js/head.min.js"></script>
  <script src="js/reveal.min.js"></script>

  <script>

   // Full list of configuration options available here:
   // https://github.com/hakimel/reveal.js#configuration
   Reveal.initialize({
    controls: true,
    progress: true,
    history: true,
    center: true,

    theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
    transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

    // Parallax scrolling
    // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
    // parallaxBackgroundSize: '2100px 900px',

    // Optional libraries used to extend on reveal.js
    dependencies: [
     { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
     { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
     { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
     { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
     { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
     { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
    ]
   });

  </script>

 </body>
</html>
