{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Live Plotting : Theano, Bokeh and iPython/Jupyter\n",
      "\n",
      "http://blocks.readthedocs.org/en/latest/plotting.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Producing nice plots from blocks requires 'blocks-extra', which happens to already be included in the requirements.txt file in this repo : "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# . env/bin/activate\n",
      "# pip install -r requirements.txt "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And, so that we can do dynamic plotting, start the ``bokeh-server`` on the command line :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# bokeh-server"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test this using this code snippet from : http://bokeh.pydata.org/en/latest/docs/user_guide/embed.html#id3 :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from bokeh.embed import notebook_div\n",
      "#div = notebook_div(plot)\n",
      "\n",
      "# Or, using the same page's cryptic hints :\n",
      "from bokeh.io import output_notebook, show\n",
      "output_notebook(hide_banner=True)\n",
      "\n",
      "from bokeh.plotting import figure\n",
      "\n",
      "plot = figure()\n",
      "plot.circle([1,2], [3,4])\n",
      "\n",
      "show(plot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that your plotting server is up and running, start your main loop and pass the Plot extension. Consider this example of fitting the function $f(x)=x^a$ to $f(x)=x^2$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "a = theano.shared(3.)\n",
      "a.name = 'a'\n",
      "x = theano.tensor.scalar('data')\n",
      "cost = abs(x ** 2 - x ** a)\n",
      "cost.name = 'cost'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We train on a 150 random points in [0,1] :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import numpy\n",
      "from fuel.streams import DataStream\n",
      "from fuel.datasets import IterableDataset\n",
      "data_stream = DataStream(IterableDataset(\n",
      "  numpy.random.rand(150).astype(theano.config.floatX)\n",
      "))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let\u2019s train with gradient descent and plot the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from blocks.main_loop import MainLoop\n",
      "from blocks.algorithms import GradientDescent, Scale\n",
      "from blocks.extensions import FinishAfter\n",
      "from blocks.extensions.monitoring import TrainingDataMonitoring\n",
      "from blocks.extras.extensions.plot import Plot  \n",
      "main_loop = MainLoop(\n",
      "     model=None, data_stream=data_stream,\n",
      "     algorithm=GradientDescent(cost=cost,\n",
      "                               params=[a],\n",
      "                               step_rule=Scale(learning_rate=0.1)),\n",
      "     extensions=[FinishAfter(after_n_epochs=1),\n",
      "                 TrainingDataMonitoring([cost, a], after_batch=True),\n",
      "                 ])  \n",
      "main_loop.run() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}